# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

securitycloud.test.number=123
securitycloud.test.countWindow.batchSize=1000000
securitycloud.test.countWindow.limit=5000000

# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=samza_test_count

# YARN
#yarn.package.path=http://10.16.31.214:8000/hello-samza-0.8.0-dist.tar.gz
#yarn.package.path=file:///home/dazle/securitycloud/samza/target/hello-samza-0.8.0-dist.tar.gz
yarn.package.path=http://100.64.25.101:8000/hello-samza-0.8.0-dist.tar.gz
yarn.container.count=1

# Task
task.class=samza.samza_test.SamzaTestEmpty
task.inputs=kafka.samza-data-5
#task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
#task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
#task.checkpoint.replication.factor=1
task.consumer.batch.size=1000

# Serializers
#serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
#serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
#serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
#systems.kafka.samza.msg.serde=json
#systems.kafka.consumer.zookeeper.connect=10.16.31.201:2181/
#systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.consumer.zookeeper.connect=100.64.25.107:2181/
systems.kafka.consumer.auto.offset.reset=largest
#systems.kafka.producer.metadata.broker.list=10.16.31.201:9092
#systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.metadata.broker.list=100.64.25.107:9092
systems.kafka.producer.producer.type=async
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1
#systems.filereader.samza.factory=samza.samza_test.FileReaderSystemFactory
systems.kafka.streams.samza-data-5.samza.reset.offset=true
systems.kafka.streams.samza-data-5.samza.offset.default=oldest

# Key-value storage
#stores.samza-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
#stores.samza-store.changelog=kafka.samza-stats-changelog
#stores.samza-store.key.serde=string
#stores.samza-store.msg.serde=integer

# Normally, we'd set this much higher, but we want things to look snappy in the demo.
#stores.samza-store.write.batch.size=1000
#stores.samza-store.object.cache.size=1000

# Define a metrics reporter called "snapshot", which publishes metrics
# every 60 seconds.
#metrics.reporters=snapshot
#metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
#metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Tell the snapshot reporter to publish to a topic called "metrics"
# in the "kafka" system.
metrics.reporter.snapshot.stream=kafka.metrics

# Encode metrics data as JSON.
#serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
#systems.kafka.streams.metrics.samza.msg.serde=metrics
